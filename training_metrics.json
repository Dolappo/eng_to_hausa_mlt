{
  "config": {
    "data_file": "Eng_Hausa.csv",
    "output_dir": "./results",
    "model_dir": "./final_model",
    "metrics_file": "./training_metrics.json",
    "summary_file": "./training_summary.txt",
    "model_name": "Helsinki-NLP/opus-mt-ha-en",
    "max_length": 40,
    "num_epochs": 10,
    "batch_size": 1,
    "gradient_accumulation_steps": 16,
    "learning_rate": 3e-05,
    "warmup_steps": 300,
    "eval_steps": 100,
    "save_steps": 100,
    "logging_steps": 25,
    "min_text_length": 5,
    "max_text_length": 80
  },
  "start_time": "2025-11-16T14:23:34.285083",
  "end_time": "2025-11-16T16:17:47.129046",
  "metrics_history": {
    "step": [
      25,
      50,
      75,
      100,
      100,
      125,
      150,
      175,
      200,
      200,
      225,
      250,
      275,
      300,
      300,
      325,
      350,
      375,
      400,
      400,
      425,
      450,
      475,
      500,
      500,
      525,
      550,
      575,
      600,
      600,
      625,
      650,
      675,
      700,
      700,
      725,
      750,
      775,
      800,
      800,
      825,
      850,
      875,
      900,
      900,
      925,
      950,
      975,
      1000,
      1000,
      1025,
      1050,
      1075,
      1100,
      1100,
      1125,
      1150,
      1175,
      1200,
      1200,
      1225,
      1250,
      1275,
      1300,
      1300,
      1325,
      1350,
      1375,
      1400,
      1400,
      1425,
      1450,
      1475,
      1500,
      1500,
      1525,
      1550,
      1575,
      1600,
      1600,
      1625,
      1650,
      1675,
      1700,
      1700,
      1725,
      1750,
      1775,
      1800,
      1800,
      1825,
      1850,
      1875,
      1900,
      1900,
      1925,
      1950,
      1975,
      2000,
      2000,
      2025,
      2050
    ],
    "loss": [
      4.6259,
      4.6317,
      4.6207,
      4.38,
      4.5299,
      4.5571,
      4.2787,
      4.5574,
      4.4859,
      4.2301,
      4.5673,
      4.4781,
      4.3583,
      4.3431,
      4.242,
      4.3577,
      4.1544,
      4.336,
      4.3554,
      4.3889,
      4.457,
      4.5285,
      4.6893,
      4.9692,
      5.0822,
      5.0552,
      5.0959,
      4.711,
      4.4905,
      4.3246,
      4.2347,
      3.9085,
      3.9536,
      3.6661,
      3.6147,
      3.6665,
      3.3908,
      3.4112,
      3.3755,
      3.4369,
      3.3265,
      3.0775,
      3.1921,
      3.0852,
      3.1618,
      3.0765,
      3.082,
      3.1199,
      3.0602,
      2.963,
      2.8403,
      2.9286,
      3.0496,
      2.9136,
      2.9179,
      2.9067,
      2.8494,
      2.5939,
      2.6969,
      2.7244,
      2.832,
      2.7694,
      2.7746,
      2.6788,
      2.7159,
      2.7502,
      2.6498,
      2.5697,
      2.6628,
      2.5697,
      2.6012,
      2.7805,
      2.706,
      2.5665,
      2.6167,
      2.5633,
      2.4521,
      2.6548,
      2.5862,
      2.5604,
      2.6981,
      2.5606
    ],
    "lr": [
      2.4000000000000003e-06,
      4.9e-06,
      7.4e-06,
      9.9e-06,
      1.24e-05,
      1.49e-05,
      1.74e-05,
      1.99e-05,
      2.2400000000000002e-05,
      2.49e-05,
      2.7400000000000002e-05,
      2.9900000000000002e-05,
      2.959090909090909e-05,
      2.916477272727273e-05,
      2.8738636363636365e-05,
      2.83125e-05,
      2.788636363636364e-05,
      2.746022727272727e-05,
      2.703409090909091e-05,
      2.6607954545454548e-05,
      2.618181818181818e-05,
      2.575568181818182e-05,
      2.5329545454545457e-05,
      2.490340909090909e-05,
      2.4477272727272728e-05,
      2.4051136363636366e-05,
      2.3624999999999998e-05,
      2.3198863636363637e-05,
      2.2772727272727272e-05,
      2.234659090909091e-05,
      2.1920454545454546e-05,
      2.149431818181818e-05,
      2.106818181818182e-05,
      2.0642045454545455e-05,
      2.021590909090909e-05,
      1.978977272727273e-05,
      1.9363636363636364e-05,
      1.89375e-05,
      1.8511363636363638e-05,
      1.808522727272727e-05,
      1.765909090909091e-05,
      1.7232954545454547e-05,
      1.6806818181818183e-05,
      1.6380681818181818e-05,
      1.5954545454545456e-05,
      1.552840909090909e-05,
      1.5102272727272729e-05,
      1.4676136363636364e-05,
      1.4249999999999999e-05,
      1.3823863636363638e-05,
      1.3397727272727273e-05,
      1.2971590909090908e-05,
      1.2545454545454545e-05,
      1.2119318181818182e-05,
      1.1693181818181819e-05,
      1.1267045454545454e-05,
      1.0840909090909091e-05,
      1.0414772727272728e-05,
      9.988636363636363e-06,
      9.5625e-06,
      9.136363636363637e-06,
      8.710227272727273e-06,
      8.28409090909091e-06,
      7.857954545454545e-06,
      7.4318181818181825e-06,
      7.005681818181819e-06,
      6.579545454545455e-06,
      6.153409090909091e-06,
      5.727272727272728e-06,
      5.301136363636364e-06,
      4.875e-06,
      4.448863636363636e-06,
      4.022727272727273e-06,
      3.596590909090909e-06,
      3.1704545454545456e-06,
      2.744318181818182e-06,
      2.318181818181818e-06,
      1.8920454545454545e-06,
      1.465909090909091e-06,
      1.0397727272727273e-06,
      6.136363636363637e-07,
      1.875e-07
    ],
    "epoch": [
      0.1218026796589525,
      0.243605359317905,
      0.3654080389768575,
      0.48721071863581,
      0.48721071863581,
      0.6090133982947625,
      0.730816077953715,
      0.8526187576126675,
      0.97442143727162,
      0.97442143727162,
      1.092570036540804,
      1.2143727161997564,
      1.3361753958587088,
      1.4579780755176615,
      1.4579780755176615,
      1.5797807551766139,
      1.7015834348355665,
      1.823386114494519,
      1.9451887941534713,
      1.9451887941534713,
      2.063337393422655,
      2.185140073081608,
      2.3069427527405604,
      2.428745432399513,
      2.428745432399513,
      2.550548112058465,
      2.6723507917174176,
      2.7941534713763705,
      2.915956151035323,
      2.915956151035323,
      3.0341047503045067,
      3.155907429963459,
      3.2777101096224115,
      3.3995127892813644,
      3.3995127892813644,
      3.5213154689403168,
      3.643118148599269,
      3.7649208282582216,
      3.886723507917174,
      3.886723507917174,
      4.004872107186358,
      4.12667478684531,
      4.248477466504263,
      4.370280146163216,
      4.370280146163216,
      4.492082825822168,
      4.613885505481121,
      4.735688185140073,
      4.857490864799026,
      4.857490864799026,
      4.9792935444579784,
      5.097442143727162,
      5.219244823386115,
      5.341047503045067,
      5.341047503045067,
      5.4628501827040195,
      5.584652862362972,
      5.706455542021924,
      5.828258221680877,
      5.828258221680877,
      5.950060901339829,
      6.068209500609013,
      6.190012180267966,
      6.311814859926918,
      6.311814859926918,
      6.433617539585871,
      6.555420219244823,
      6.677222898903776,
      6.799025578562729,
      6.799025578562729,
      6.920828258221681,
      7.038976857490865,
      7.160779537149818,
      7.28258221680877,
      7.28258221680877,
      7.404384896467723,
      7.5261875761266745,
      7.647990255785627,
      7.769792935444579,
      7.769792935444579,
      7.891595615103532,
      8.009744214372716,
      8.131546894031668,
      8.25334957369062,
      8.25334957369062,
      8.375152253349574,
      8.496954933008526,
      8.618757612667478,
      8.740560292326432,
      8.740560292326432,
      8.862362971985384,
      8.984165651644336,
      9.10231425091352,
      9.224116930572473,
      9.224116930572473,
      9.345919610231425,
      9.467722289890377,
      9.58952496954933,
      9.711327649208283,
      9.711327649208283,
      9.833130328867234,
      9.954933008526188
    ]
  },
  "epoch_stats": [
    {
      "epoch": 0,
      "metrics": {
        "loss": 4.572900000000001,
        "grad_norm": 7825073327.984157,
        "learning_rate": 9.911111111111111e-06,
        "step": 109.18181818181819,
        "eval_loss": 4.705190658569336,
        "eval_bleu": 5.876841630974475,
        "eval_runtime": 44.042,
        "eval_samples_per_second": 3.95,
        "eval_steps_per_second": 3.95
      }
    },
    {
      "epoch": 1,
      "metrics": {
        "loss": 4.402211111111111,
        "grad_norm": 130639.29049597846,
        "learning_rate": 2.6700757575757574e-05,
        "step": 300.0,
        "eval_loss": 4.592844327290853,
        "eval_bleu": 5.785636661486319,
        "eval_runtime": 40.70473333333333,
        "eval_samples_per_second": 4.250333333333334,
        "eval_steps_per_second": 4.250333333333334
      }
    },
    {
      "epoch": 2,
      "metrics": {
        "loss": 4.470711111111111,
        "grad_norm": 11041.462059020996,
        "learning_rate": 2.6607954545454545e-05,
        "step": 500.0,
        "eval_loss": 4.7420376141866045,
        "eval_bleu": 4.66363303412298,
        "eval_runtime": 97.43666666666667,
        "eval_samples_per_second": 2.4666666666666663,
        "eval_steps_per_second": 2.4666666666666663
      }
    },
    {
      "epoch": 3,
      "metrics": {
        "loss": 4.652422222222223,
        "grad_norm": 117.91762669881184,
        "learning_rate": 2.3198863636363637e-05,
        "step": 700.0,
        "eval_loss": 4.69798485438029,
        "eval_bleu": 2.5164829535480737,
        "eval_runtime": 172.36980000000003,
        "eval_samples_per_second": 1.0233333333333332,
        "eval_steps_per_second": 1.0233333333333332
      }
    },
    {
      "epoch": 4,
      "metrics": {
        "loss": 3.537977777777778,
        "grad_norm": 49.53821224636502,
        "learning_rate": 1.9363636363636364e-05,
        "step": 929.5454545454545,
        "eval_loss": 3.7650641202926636,
        "eval_bleu": 8.555342312698937,
        "eval_runtime": 43.39045,
        "eval_samples_per_second": 3.9939999999999998,
        "eval_steps_per_second": 3.9939999999999998
      }
    },
    {
      "epoch": 5,
      "metrics": {
        "loss": 3.1313,
        "grad_norm": 23.74220985836453,
        "learning_rate": 1.5954545454545453e-05,
        "step": 1129.5454545454545,
        "eval_loss": 3.5909348726272583,
        "eval_bleu": 10.730095071600854,
        "eval_runtime": 38.629,
        "eval_samples_per_second": 4.4785,
        "eval_steps_per_second": 4.4785
      }
    },
    {
      "epoch": 6,
      "metrics": {
        "loss": 2.936588888888889,
        "grad_norm": 23.629652235243057,
        "learning_rate": 1.2545454545454545e-05,
        "step": 1329.5454545454545,
        "eval_loss": 3.500369668006897,
        "eval_bleu": 10.678896305122594,
        "eval_runtime": 40.44685,
        "eval_samples_per_second": 4.276999999999999,
        "eval_steps_per_second": 4.276999999999999
      }
    },
    {
      "epoch": 7,
      "metrics": {
        "loss": 2.737255555555556,
        "grad_norm": 38.04815991719564,
        "learning_rate": 9.136363636363637e-06,
        "step": 1529.5454545454545,
        "eval_loss": 3.452000856399536,
        "eval_bleu": 11.759775534933086,
        "eval_runtime": 40.21165,
        "eval_samples_per_second": 4.3025,
        "eval_steps_per_second": 4.3025
      }
    },
    {
      "epoch": 8,
      "metrics": {
        "loss": 2.6507111111111112,
        "grad_norm": 22.671637217203777,
        "learning_rate": 5.301136363636364e-06,
        "step": 1750.0,
        "eval_loss": 3.409380793571472,
        "eval_bleu": 11.849460328526842,
        "eval_runtime": 41.279349999999994,
        "eval_samples_per_second": 4.194000000000001,
        "eval_steps_per_second": 4.194000000000001
      }
    },
    {
      "epoch": 9,
      "metrics": {
        "loss": 2.5843,
        "grad_norm": 16.671787791781956,
        "learning_rate": 1.8920454545454549e-06,
        "step": 1950.0,
        "eval_loss": 3.394080877304077,
        "eval_bleu": 11.739040746081955,
        "eval_runtime": 39.45075,
        "eval_samples_per_second": 4.3855,
        "eval_steps_per_second": 4.3855
      }
    }
  ]
}